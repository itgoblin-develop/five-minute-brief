#!/usr/bin/env python3
"""
Phase 2: ì£¼ì œ í´ëŸ¬ìŠ¤í„°ë§ ëª¨ë“ˆ
- TF-IDF ë²¡í„°í™” (char_wb n-gramìœ¼ë¡œ í•œêµ­ì–´ ìµœì í™”)
- ê³„ì¸µì  êµ°ì§‘í™” (Agglomerative Clustering)
- ì¹´í…Œê³ ë¦¬ë³„ ëª©í‘œ í´ëŸ¬ìŠ¤í„° ìˆ˜ ê¸°ë°˜ ì œì–´
"""

import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import AgglomerativeClustering


# ì¹´í…Œê³ ë¦¬ë³„ ëª©í‘œ í´ëŸ¬ìŠ¤í„° ìˆ˜
DEFAULT_TARGETS = {
    "Economy": {"min": 5, "max": 7},
    "Money": {"min": 3, "max": 5},
    "Society": {"min": 2, "max": 4},
    "Trend": {"min": 4, "max": 6},
}


class ArticleClusterer:
    """ë‰´ìŠ¤ ê¸°ì‚¬ ì£¼ì œ í´ëŸ¬ìŠ¤í„°ë§ (í•œêµ­ì–´ ìµœì í™”)"""

    def __init__(self, config: dict = None):
        config = config or {}
        self.max_features = config.get("max_features", 5000)
        self.max_cluster_size = config.get("max_cluster_size", 10)
        self.targets = config.get("targets", DEFAULT_TARGETS)

        # output_targets í˜•ì‹ë„ í˜¸í™˜
        if not self.targets or all(isinstance(v, float) for v in self.targets.values()):
            self.targets = DEFAULT_TARGETS

    def cluster_by_category(self, articles_by_category: Dict[str, List[dict]]) -> Dict[str, List[List[dict]]]:
        """
        ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê¸°ì‚¬ë¥¼ í´ëŸ¬ìŠ¤í„°ë§

        Args:
            articles_by_category: {"Economy": [...], "Money": [...], ...}

        Returns:
            ì¹´í…Œê³ ë¦¬ë³„ í´ëŸ¬ìŠ¤í„° ë¦¬ìŠ¤íŠ¸
            {"Economy": [[ê¸°ì‚¬1, ê¸°ì‚¬2], [ê¸°ì‚¬3], ...], ...}
        """
        result = {}

        for category, articles in articles_by_category.items():
            if not articles:
                result[category] = []
                continue

            if len(articles) == 1:
                result[category] = [articles]
                print(f"     {category}: 1ê±´ â†’ 1ê°œ í´ëŸ¬ìŠ¤í„°")
                continue

            # ëª©í‘œ í´ëŸ¬ìŠ¤í„° ìˆ˜ ê²°ì •
            target = self.targets.get(category, {"min": 3, "max": 6})
            if isinstance(target, dict):
                target_n = (target.get("min", 3) + target.get("max", 6)) // 2
            else:
                target_n = int(target)

            # ê¸°ì‚¬ ìˆ˜ê°€ ëª©í‘œë³´ë‹¤ ì ìœ¼ë©´ ì¡°ì •
            target_n = min(target_n, len(articles))

            clusters = self._cluster_articles(articles, target_n)

            # ëŒ€í˜• í´ëŸ¬ìŠ¤í„° ë¶„ë¦¬
            split_clusters = []
            for cluster in clusters:
                if len(cluster) > self.max_cluster_size:
                    sub_n = max(2, len(cluster) // self.max_cluster_size + 1)
                    sub_clusters = self._cluster_articles(cluster, sub_n)
                    split_clusters.extend(sub_clusters)
                else:
                    split_clusters.append(cluster)

            # ëŒ€í‘œ ê¸°ì‚¬ ë§ˆí‚¹ (trend_score ìµœê³ )
            for cluster in split_clusters:
                representative = self._get_representative(cluster)
                for article in cluster:
                    article["_is_representative"] = (article is representative)

            result[category] = split_clusters
            sizes = sorted([len(c) for c in split_clusters], reverse=True)
            print(f"     {category}: {len(articles)}ê±´ â†’ {len(split_clusters)}ê°œ í´ëŸ¬ìŠ¤í„° (ëª©í‘œ: {target_n}, í¬ê¸°: {sizes[:5]}{'...' if len(sizes) > 5 else ''})")

        total_clusters = sum(len(v) for v in result.values())
        print(f"  ğŸ“Š í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼: ì´ {total_clusters}ê°œ í´ëŸ¬ìŠ¤í„°")

        return result

    def _cluster_articles(self, articles: List[dict], n_clusters: int) -> List[List[dict]]:
        """TF-IDF + ê³„ì¸µì  êµ°ì§‘í™”ë¡œ ê¸°ì‚¬ ê·¸ë£¹í•‘"""

        # ì œëª© + ë³¸ë¬¸ ì• 300ìë¥¼ ê²°í•©í•˜ì—¬ í…ìŠ¤íŠ¸ ìƒì„±
        texts = []
        for a in articles:
            title = a.get("title", "")
            content = a.get("content", "")[:300]
            texts.append(f"{title} {content}")

        # TF-IDF ë²¡í„°í™” (í•œêµ­ì–´ ìµœì í™”: char_wb + 2~4 n-gram)
        vectorizer = TfidfVectorizer(
            max_features=self.max_features,
            analyzer="char_wb",
            ngram_range=(2, 4),
            min_df=1,
            max_df=0.85,
        )

        try:
            tfidf_matrix = vectorizer.fit_transform(texts)
        except ValueError as e:
            print(f"  âš ï¸ TF-IDF ë²¡í„°í™” ì‹¤íŒ¨: {e}")
            return [[a] for a in articles]

        if tfidf_matrix.shape[0] < 2:
            return [articles]

        # n_clustersê°€ ê¸°ì‚¬ ìˆ˜ ì´ìƒì´ë©´ ê°œë³„ í´ëŸ¬ìŠ¤í„°
        if n_clusters >= len(articles):
            return [[a] for a in articles]

        # ê³„ì¸µì  êµ°ì§‘í™” (n_clusters ì§ì ‘ ì§€ì •)
        try:
            clustering = AgglomerativeClustering(
                n_clusters=n_clusters,
                metric="cosine",
                linkage="average",
            )
            labels = clustering.fit_predict(tfidf_matrix.toarray())
        except Exception as e:
            print(f"  âš ï¸ í´ëŸ¬ìŠ¤í„°ë§ ì‹¤íŒ¨: {e}")
            return [[a] for a in articles]

        # ë¼ë²¨ë³„ ê·¸ë£¹í•‘
        clusters = {}
        for idx, label in enumerate(labels):
            clusters.setdefault(label, []).append(articles[idx])

        # í´ëŸ¬ìŠ¤í„°ë¥¼ í¬ê¸° ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
        sorted_clusters = sorted(clusters.values(), key=len, reverse=True)

        return sorted_clusters

    def _get_representative(self, cluster: List[dict]) -> dict:
        """í´ëŸ¬ìŠ¤í„° ë‚´ trend_scoreê°€ ê°€ì¥ ë†’ì€ ê¸°ì‚¬ë¥¼ ëŒ€í‘œ ê¸°ì‚¬ë¡œ ì„ ì •"""
        return max(cluster, key=lambda a: a.get("trend_score", 0))


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="Phase 2: ì£¼ì œ í´ëŸ¬ìŠ¤í„°ë§")
    parser.add_argument("--input", required=True, help="ì „ì²˜ë¦¬ëœ ê¸°ì‚¬ JSON íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output", default=None, help="í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ ì¶œë ¥ ê²½ë¡œ")
    args = parser.parse_args()

    print("ğŸš€ Phase 2: ì£¼ì œ í´ëŸ¬ìŠ¤í„°ë§ ì‹œì‘")

    with open(args.input, "r", encoding="utf-8") as f:
        articles_by_category = json.load(f)

    clusterer = ArticleClusterer()
    clusters = clusterer.cluster_by_category(articles_by_category)

    if args.output:
        output_data = {}
        for category, cluster_list in clusters.items():
            output_data[category] = []
            for cluster in cluster_list:
                output_data[category].append({
                    "cluster_size": len(cluster),
                    "representative": next(
                        (a["title"] for a in cluster if a.get("_is_representative")),
                        cluster[0]["title"] if cluster else ""
                    ),
                    "articles": cluster,
                })
        with open(args.output, "w", encoding="utf-8") as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"âœ… ê²°ê³¼ ì €ì¥: {args.output}")
    else:
        for category, cluster_list in clusters.items():
            print(f"\n  [{category}]")
            for i, cluster in enumerate(cluster_list):
                rep = next((a for a in cluster if a.get("_is_representative")), cluster[0])
                print(f"    í´ëŸ¬ìŠ¤í„° {i+1} ({len(cluster)}ê±´): {rep['title'][:50]}...")
