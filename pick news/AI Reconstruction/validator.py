#!/usr/bin/env python3
"""
Phase 4: í’ˆì§ˆ ê²€ì¦ ëª¨ë“ˆ
- 5ê°œ í•„ë“œ ê¸¸ì´/í˜•ì‹ ê²€ì¦
- bullet_summary, hashtags ìë™ ë³´ì •
- ì›ë¬¸ ìœ ì‚¬ë„ ì²´í¬
"""

import re
from typing import Dict, List, Tuple

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity


class ArticleValidator:
    """ì¬êµ¬ì„± ê¸°ì‚¬ í’ˆì§ˆ ê²€ì¦ê¸°"""

    def __init__(self, config: dict = None):
        config = config or {}
        self.title_length = config.get("title_length", {"min": 5, "max": 30})
        self.summary_length = config.get("summary_length", {"min": 50, "max": 200})
        self.bullet_count = config.get("bullet_summary_count", 3)
        self.bullet_item_length = config.get("bullet_summary_item_length", {"min": 10, "max": 50})
        self.content_length = config.get("content_length", {"min": 300, "max": 700})
        self.content_paragraphs = config.get("content_paragraphs", {"min": 2, "max": 5})
        self.hashtag_count = config.get("hashtag_count", {"min": 3, "max": 5})
        self.hashtag_item_length = config.get("hashtag_item_length", {"min": 2, "max": 8})
        self.originality_threshold = config.get("originality_threshold", 0.8)

    def validate_all(self, articles: List[dict]) -> List[dict]:
        """ì „ì²´ ê¸°ì‚¬ ê²€ì¦ + ìë™ ë³´ì •"""
        validated = []

        for article in articles:
            # ìë™ ë³´ì • ì ìš©
            article = self._auto_correct(article)

            # ê²€ì¦
            errors = self._validate_article(article)

            if errors:
                print(f"  âš ï¸ ê²€ì¦ ê²½ê³  [{article.get('title', '')[:20]}...]: {', '.join(errors)}")

            validated.append(article)

        passed = len(validated)
        print(f"  ğŸ“Š ê²€ì¦ ê²°ê³¼: {passed}/{len(articles)}ê±´ í†µê³¼")

        return validated

    def _auto_correct(self, article: dict) -> dict:
        """ìë™ ë³´ì • ì ìš©"""

        # title ë³´ì •
        title = article.get("title", "")
        if len(title) > self.title_length["max"]:
            article["title"] = title[:self.title_length["max"]]

        # summary ë³´ì •
        summary = article.get("summary", "")
        if len(summary) > self.summary_length["max"]:
            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            truncated = summary[:self.summary_length["max"]]
            last_period = truncated.rfind('.')
            if last_period > self.summary_length["max"] * 0.6:
                article["summary"] = truncated[:last_period + 1]
            else:
                article["summary"] = truncated

        # bullet_summary ë³´ì •
        article["bullet_summary"] = self._fix_bullet_summary(
            article.get("bullet_summary", []),
            article.get("title", ""),
        )

        # content ë³´ì •
        content = article.get("content", "")
        if len(content) > self.content_length["max"]:
            # ë¬¸ë‹¨ ê²½ê³„ì—ì„œ ìë¥´ê¸°
            paragraphs = content.split("\n\n")
            truncated = ""
            for p in paragraphs:
                if len(truncated) + len(p) + 2 <= self.content_length["max"]:
                    truncated += ("\n\n" + p) if truncated else p
                else:
                    break
            article["content"] = truncated if truncated else content[:self.content_length["max"]]

        # hashtags ë³´ì •
        article["hashtags"] = self._fix_hashtags(
            article.get("hashtags", []),
            article.get("title", ""),
            article.get("content", ""),
        )

        return article

    def _validate_article(self, article: dict) -> List[str]:
        """ê°œë³„ ê¸°ì‚¬ ê²€ì¦, ê²½ê³  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        errors = []

        # title ê¸¸ì´
        title_len = len(article.get("title", ""))
        if title_len < self.title_length["min"]:
            errors.append(f"title ë„ˆë¬´ ì§§ìŒ ({title_len}ì)")

        # summary ê¸¸ì´
        summary_len = len(article.get("summary", ""))
        if summary_len < self.summary_length["min"]:
            errors.append(f"summary ë„ˆë¬´ ì§§ìŒ ({summary_len}ì)")

        # bullet_summary ê°œìˆ˜
        bullets = article.get("bullet_summary", [])
        if len(bullets) != self.bullet_count:
            errors.append(f"bullet_summary {len(bullets)}ê°œ (ê¸°ëŒ€: {self.bullet_count}ê°œ)")

        # content ê¸¸ì´
        content_len = len(article.get("content", ""))
        if content_len < self.content_length["min"]:
            errors.append(f"content ë„ˆë¬´ ì§§ìŒ ({content_len}ì)")

        # content ë¬¸ë‹¨ ìˆ˜
        paragraphs = article.get("content", "").split("\n\n")
        para_count = len([p for p in paragraphs if p.strip()])
        if para_count < self.content_paragraphs["min"]:
            errors.append(f"content ë¬¸ë‹¨ {para_count}ê°œ (ìµœì†Œ: {self.content_paragraphs['min']})")

        # hashtags ê°œìˆ˜
        tags = article.get("hashtags", [])
        if len(tags) < self.hashtag_count["min"]:
            errors.append(f"hashtags {len(tags)}ê°œ (ìµœì†Œ: {self.hashtag_count['min']}ê°œ)")

        return errors

    def _fix_bullet_summary(self, bullet_summary, title: str = "") -> List[str]:
        """bullet_summaryë¥¼ ì •í™•íˆ 3ê°œë¡œ ë³´ì •"""

        if not isinstance(bullet_summary, list):
            # ë¬¸ìì—´ì´ë©´ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
            if isinstance(bullet_summary, str):
                bullet_summary = [s.strip() for s in bullet_summary.split('.') if s.strip()]
            else:
                bullet_summary = []

        # ê° í•­ëª©ì„ ë¬¸ìì—´ë¡œ ë³€í™˜ + ê¸¸ì´ ë³´ì •
        cleaned = []
        for item in bullet_summary:
            item = str(item).strip()
            if not item:
                continue
            if len(item) > self.bullet_item_length["max"]:
                item = item[:self.bullet_item_length["max"]]
            cleaned.append(item)

        # 3ê°œ ë¯¸ë§Œì´ë©´ ì±„ìš°ê¸°
        while len(cleaned) < self.bullet_count:
            if title and len(cleaned) == 0:
                cleaned.append(title[:40])
            elif len(cleaned) == 1:
                cleaned.append("ê´€ë ¨ ì„¸ë¶€ ë‚´ìš© í™•ì¸ í•„ìš”")
            else:
                cleaned.append("ì¶”ê°€ ì •ë³´ëŠ” ë³¸ë¬¸ì„ ì°¸ì¡°í•˜ì„¸ìš”")

        # 3ê°œ ì´ˆê³¼ë©´ ìë¥´ê¸°
        return cleaned[:self.bullet_count]

    def _fix_hashtags(self, hashtags, title: str = "", content: str = "") -> List[str]:
        """hashtagsë¥¼ 3~5ê°œë¡œ ë³´ì •, '#' ì œê±°"""

        if not isinstance(hashtags, list):
            hashtags = []

        # '#' ì œê±° ë° ê¸¸ì´ í•„í„°ë§
        cleaned = []
        for tag in hashtags:
            tag = str(tag).strip().lstrip('#')
            if self.hashtag_item_length["min"] <= len(tag) <= self.hashtag_item_length["max"]:
                if tag not in cleaned:  # ì¤‘ë³µ ì œê±°
                    cleaned.append(tag)

        # 3ê°œ ë¯¸ë§Œì´ë©´ ì œëª©/ë³¸ë¬¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        if len(cleaned) < self.hashtag_count["min"]:
            words = re.findall(r'[ê°€-í£]{2,6}', title + " " + content[:200])
            # ë¹ˆë„ìˆœ ì •ë ¬
            word_freq = {}
            for w in words:
                if w not in cleaned:
                    word_freq[w] = word_freq.get(w, 0) + 1
            sorted_words = sorted(word_freq.keys(), key=lambda w: word_freq[w], reverse=True)
            for word in sorted_words:
                if len(cleaned) >= self.hashtag_count["min"]:
                    break
                cleaned.append(word)

        return cleaned[:self.hashtag_count["max"]]

    def check_originality(self, original_contents: List[str], reconstructed_content: str,
                          threshold: float = None) -> Tuple[bool, float]:
        """
        ì›ë¬¸ê³¼ ì¬êµ¬ì„± ì½˜í…ì¸ ì˜ ìœ ì‚¬ë„ ì²´í¬

        Returns:
            (í†µê³¼ ì—¬ë¶€, ìµœëŒ€ ìœ ì‚¬ë„ ê°’)
        """
        threshold = threshold or self.originality_threshold

        if not original_contents or not reconstructed_content:
            return True, 0.0

        # ë¹ˆ ë¬¸ìì—´ í•„í„°ë§
        valid_originals = [c for c in original_contents if c.strip()]
        if not valid_originals:
            return True, 0.0

        all_texts = valid_originals + [reconstructed_content]

        try:
            vectorizer = TfidfVectorizer(max_features=1000)
            tfidf = vectorizer.fit_transform(all_texts)

            reconstructed_vec = tfidf[-1]
            max_similarity = 0.0
            for i in range(len(valid_originals)):
                sim = cosine_similarity(tfidf[i], reconstructed_vec)[0][0]
                max_similarity = max(max_similarity, sim)

            passed = max_similarity < threshold
            return passed, max_similarity
        except Exception as e:
            print(f"  âš ï¸ ìœ ì‚¬ë„ ì²´í¬ ì‹¤íŒ¨: {e}")
            return True, 0.0


if __name__ == "__main__":
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
    validator = ArticleValidator()

    test_article = {
        "title": "í…ŒìŠ¤íŠ¸ ì œëª©ì…ë‹ˆë‹¤ ì´ê²ƒì€ ë§¤ìš° ê¸´ ì œëª©ì…ë‹ˆë‹¤ ì‚¼ì‹­ìë¥¼ ì´ˆê³¼í•˜ëŠ” ì œëª©",
        "summary": "ìš”ì•½ í…ŒìŠ¤íŠ¸",
        "bullet_summary": ["í¬ì¸íŠ¸1", "í¬ì¸íŠ¸2"],
        "content": "ë³¸ë¬¸ ë‚´ìš©ì…ë‹ˆë‹¤.",
        "hashtags": ["#íƒœê·¸1", "íƒœê·¸2", "ì´ê²ƒì€ë§¤ìš°ê¸´í•´ì‹œíƒœê·¸ì…ë‹ˆë‹¤"],
    }

    corrected = validator._auto_correct(test_article.copy())
    print("ë³´ì • ì „:", test_article)
    print("ë³´ì • í›„:", corrected)
    print("bullet_summary:", corrected["bullet_summary"])
    print("hashtags:", corrected["hashtags"])
